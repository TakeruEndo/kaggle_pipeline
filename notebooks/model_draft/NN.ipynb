{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../data/raw/train_2.csv\")\n",
    "test = pd.read_csv(\"../../data/raw/test_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>3SsnPorch</th>\n      <th>Alley</th>\n      <th>BedroomAbvGr</th>\n      <th>BsmtCond</th>\n      <th>BsmtExposure</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>BsmtFinType1</th>\n      <th>...</th>\n      <th>SaleType_COD</th>\n      <th>SaleType_CWD</th>\n      <th>SaleType_Con</th>\n      <th>SaleType_ConLD</th>\n      <th>SaleType_ConLI</th>\n      <th>SaleType_ConLw</th>\n      <th>SaleType_New</th>\n      <th>SaleType_Oth</th>\n      <th>SaleType_WD</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.692623</td>\n      <td>11.686189</td>\n      <td>0.0</td>\n      <td>0.730463</td>\n      <td>1.540963</td>\n      <td>1.820334</td>\n      <td>1.540963</td>\n      <td>11.170327</td>\n      <td>0.0</td>\n      <td>1.194318</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>12.247699</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12.792276</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.730463</td>\n      <td>1.540963</td>\n      <td>1.820334</td>\n      <td>0.730463</td>\n      <td>12.062832</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>12.109016</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11.892039</td>\n      <td>11.724598</td>\n      <td>0.0</td>\n      <td>0.730463</td>\n      <td>1.540963</td>\n      <td>1.820334</td>\n      <td>1.194318</td>\n      <td>10.200343</td>\n      <td>0.0</td>\n      <td>1.194318</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>12.317171</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12.013683</td>\n      <td>11.354094</td>\n      <td>0.0</td>\n      <td>0.730463</td>\n      <td>1.540963</td>\n      <td>0.730463</td>\n      <td>1.540963</td>\n      <td>8.274266</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>11.849405</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12.510588</td>\n      <td>12.271365</td>\n      <td>0.0</td>\n      <td>0.730463</td>\n      <td>1.820334</td>\n      <td>1.820334</td>\n      <td>0.000000</td>\n      <td>10.971129</td>\n      <td>0.0</td>\n      <td>1.194318</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>12.429220</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 221 columns</p>\n</div>",
      "text/plain": "    1stFlrSF   2ndFlrSF  3SsnPorch     Alley  BedroomAbvGr  BsmtCond  \\\n0  11.692623  11.686189        0.0  0.730463      1.540963  1.820334   \n1  12.792276   0.000000        0.0  0.730463      1.540963  1.820334   \n2  11.892039  11.724598        0.0  0.730463      1.540963  1.820334   \n3  12.013683  11.354094        0.0  0.730463      1.540963  0.730463   \n4  12.510588  12.271365        0.0  0.730463      1.820334  1.820334   \n\n   BsmtExposure  BsmtFinSF1  BsmtFinSF2  BsmtFinType1  ...  SaleType_COD  \\\n0      1.540963   11.170327         0.0      1.194318  ...             0   \n1      0.730463   12.062832         0.0      0.000000  ...             0   \n2      1.194318   10.200343         0.0      1.194318  ...             0   \n3      1.540963    8.274266         0.0      0.000000  ...             0   \n4      0.000000   10.971129         0.0      1.194318  ...             0   \n\n   SaleType_CWD  SaleType_Con  SaleType_ConLD  SaleType_ConLI  SaleType_ConLw  \\\n0             0             0               0               0               0   \n1             0             0               0               0               0   \n2             0             0               0               0               0   \n3             0             0               0               0               0   \n4             0             0               0               0               0   \n\n   SaleType_New  SaleType_Oth  SaleType_WD  SalePrice  \n0             0             0            1  12.247699  \n1             0             0            1  12.109016  \n2             0             0            1  12.317171  \n3             0             0            1  11.849405  \n4             0             0            1  12.429220  \n\n[5 rows x 221 columns]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['SalePrice']\n",
    "train_x = train.drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 1093 samples, validate on 365 samples\nEpoch 1/100\n1093/1093 [==============================] - 1s 902us/step - loss: 9.1411 - mean_absolute_error: 9.1411 - val_loss: 5.5707 - val_mean_absolute_error: 5.5707\nEpoch 2/100\n1093/1093 [==============================] - 0s 71us/step - loss: 3.7876 - mean_absolute_error: 3.7876 - val_loss: 3.2461 - val_mean_absolute_error: 3.2461\nEpoch 3/100\n1093/1093 [==============================] - 0s 70us/step - loss: 2.4089 - mean_absolute_error: 2.4089 - val_loss: 1.6916 - val_mean_absolute_error: 1.6916\nEpoch 4/100\n1093/1093 [==============================] - 0s 72us/step - loss: 1.5962 - mean_absolute_error: 1.5962 - val_loss: 1.2100 - val_mean_absolute_error: 1.2100\nEpoch 5/100\n1093/1093 [==============================] - 0s 70us/step - loss: 1.3600 - mean_absolute_error: 1.3600 - val_loss: 1.0248 - val_mean_absolute_error: 1.0248\nEpoch 6/100\n1093/1093 [==============================] - 0s 71us/step - loss: 1.1197 - mean_absolute_error: 1.1197 - val_loss: 0.8405 - val_mean_absolute_error: 0.8405\nEpoch 7/100\n1093/1093 [==============================] - 0s 71us/step - loss: 1.0271 - mean_absolute_error: 1.0271 - val_loss: 0.7999 - val_mean_absolute_error: 0.7999\nEpoch 8/100\n1093/1093 [==============================] - 0s 79us/step - loss: 0.9935 - mean_absolute_error: 0.9935 - val_loss: 0.6877 - val_mean_absolute_error: 0.6877\nEpoch 9/100\n1093/1093 [==============================] - 0s 79us/step - loss: 0.9308 - mean_absolute_error: 0.9308 - val_loss: 0.6692 - val_mean_absolute_error: 0.6692\nEpoch 10/100\n1093/1093 [==============================] - 0s 74us/step - loss: 0.9045 - mean_absolute_error: 0.9045 - val_loss: 0.6378 - val_mean_absolute_error: 0.6378\nEpoch 11/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.8924 - mean_absolute_error: 0.8924 - val_loss: 0.6171 - val_mean_absolute_error: 0.6171\nEpoch 12/100\n1093/1093 [==============================] - 0s 68us/step - loss: 0.8816 - mean_absolute_error: 0.8816 - val_loss: 0.6425 - val_mean_absolute_error: 0.6425\nEpoch 13/100\n1093/1093 [==============================] - 0s 71us/step - loss: 0.8952 - mean_absolute_error: 0.8952 - val_loss: 0.7436 - val_mean_absolute_error: 0.7436\nEpoch 14/100\n1093/1093 [==============================] - 0s 69us/step - loss: 0.9018 - mean_absolute_error: 0.9018 - val_loss: 0.5801 - val_mean_absolute_error: 0.5801\nEpoch 15/100\n1093/1093 [==============================] - 0s 69us/step - loss: 0.8382 - mean_absolute_error: 0.8382 - val_loss: 0.5601 - val_mean_absolute_error: 0.5601\nEpoch 16/100\n1093/1093 [==============================] - 0s 72us/step - loss: 0.8613 - mean_absolute_error: 0.8613 - val_loss: 0.5802 - val_mean_absolute_error: 0.5802\nEpoch 17/100\n1093/1093 [==============================] - 0s 72us/step - loss: 0.8412 - mean_absolute_error: 0.8412 - val_loss: 0.5667 - val_mean_absolute_error: 0.5667\nEpoch 18/100\n1093/1093 [==============================] - 0s 72us/step - loss: 0.8027 - mean_absolute_error: 0.8027 - val_loss: 0.5647 - val_mean_absolute_error: 0.5647\nEpoch 19/100\n1093/1093 [==============================] - 0s 69us/step - loss: 0.8111 - mean_absolute_error: 0.8111 - val_loss: 0.5474 - val_mean_absolute_error: 0.5474\nEpoch 20/100\n1093/1093 [==============================] - 0s 70us/step - loss: 0.8300 - mean_absolute_error: 0.8300 - val_loss: 0.5717 - val_mean_absolute_error: 0.5717\nEpoch 21/100\n1093/1093 [==============================] - 0s 81us/step - loss: 0.7817 - mean_absolute_error: 0.7817 - val_loss: 0.6204 - val_mean_absolute_error: 0.6204\nEpoch 22/100\n1093/1093 [==============================] - 0s 72us/step - loss: 0.8324 - mean_absolute_error: 0.8324 - val_loss: 0.5717 - val_mean_absolute_error: 0.5717\nEpoch 23/100\n1093/1093 [==============================] - 0s 72us/step - loss: 0.8208 - mean_absolute_error: 0.8208 - val_loss: 0.5277 - val_mean_absolute_error: 0.5277\nEpoch 24/100\n1093/1093 [==============================] - 0s 70us/step - loss: 0.8090 - mean_absolute_error: 0.8090 - val_loss: 0.5165 - val_mean_absolute_error: 0.5165\nEpoch 25/100\n1093/1093 [==============================] - 0s 71us/step - loss: 0.7994 - mean_absolute_error: 0.7994 - val_loss: 0.5368 - val_mean_absolute_error: 0.5368\nEpoch 26/100\n1093/1093 [==============================] - 0s 70us/step - loss: 0.8165 - mean_absolute_error: 0.8165 - val_loss: 0.5374 - val_mean_absolute_error: 0.5374\nEpoch 27/100\n1093/1093 [==============================] - 0s 70us/step - loss: 0.8123 - mean_absolute_error: 0.8123 - val_loss: 0.5381 - val_mean_absolute_error: 0.5381\nEpoch 28/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.8370 - mean_absolute_error: 0.8370 - val_loss: 0.6137 - val_mean_absolute_error: 0.6137\nEpoch 29/100\n1093/1093 [==============================] - 0s 72us/step - loss: 0.8172 - mean_absolute_error: 0.8172 - val_loss: 0.6487 - val_mean_absolute_error: 0.6487\nEpoch 30/100\n1093/1093 [==============================] - 0s 70us/step - loss: 0.7557 - mean_absolute_error: 0.7557 - val_loss: 0.6028 - val_mean_absolute_error: 0.6028\nEpoch 31/100\n1093/1093 [==============================] - 0s 71us/step - loss: 0.7718 - mean_absolute_error: 0.7718 - val_loss: 0.7279 - val_mean_absolute_error: 0.7279\nEpoch 32/100\n1093/1093 [==============================] - 0s 75us/step - loss: 0.8348 - mean_absolute_error: 0.8348 - val_loss: 0.5630 - val_mean_absolute_error: 0.5630\nEpoch 33/100\n1093/1093 [==============================] - 0s 77us/step - loss: 0.7917 - mean_absolute_error: 0.7917 - val_loss: 0.5393 - val_mean_absolute_error: 0.5393\nEpoch 34/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.7604 - mean_absolute_error: 0.7604 - val_loss: 0.5430 - val_mean_absolute_error: 0.5430\nEpoch 35/100\n1093/1093 [==============================] - 0s 74us/step - loss: 0.7327 - mean_absolute_error: 0.7327 - val_loss: 0.5279 - val_mean_absolute_error: 0.5279\nEpoch 36/100\n1093/1093 [==============================] - 0s 71us/step - loss: 0.7469 - mean_absolute_error: 0.7469 - val_loss: 0.5199 - val_mean_absolute_error: 0.5199\nEpoch 37/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.7143 - mean_absolute_error: 0.7143 - val_loss: 0.5120 - val_mean_absolute_error: 0.5120\nEpoch 38/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.7725 - mean_absolute_error: 0.7725 - val_loss: 0.5586 - val_mean_absolute_error: 0.5586\nEpoch 39/100\n1093/1093 [==============================] - 0s 71us/step - loss: 0.7364 - mean_absolute_error: 0.7364 - val_loss: 0.4954 - val_mean_absolute_error: 0.4954\nEpoch 40/100\n1093/1093 [==============================] - 0s 71us/step - loss: 0.7354 - mean_absolute_error: 0.7354 - val_loss: 0.4926 - val_mean_absolute_error: 0.4926\nEpoch 41/100\n1093/1093 [==============================] - 0s 76us/step - loss: 0.7408 - mean_absolute_error: 0.7408 - val_loss: 0.4803 - val_mean_absolute_error: 0.4803\nEpoch 42/100\n1093/1093 [==============================] - 0s 87us/step - loss: 0.7290 - mean_absolute_error: 0.7290 - val_loss: 0.5004 - val_mean_absolute_error: 0.5004\nEpoch 43/100\n1093/1093 [==============================] - 0s 76us/step - loss: 0.6969 - mean_absolute_error: 0.6969 - val_loss: 0.5553 - val_mean_absolute_error: 0.5553\nEpoch 44/100\n1093/1093 [==============================] - 0s 76us/step - loss: 0.7416 - mean_absolute_error: 0.7416 - val_loss: 0.5735 - val_mean_absolute_error: 0.5735\nEpoch 45/100\n1093/1093 [==============================] - 0s 80us/step - loss: 0.7581 - mean_absolute_error: 0.7581 - val_loss: 0.5960 - val_mean_absolute_error: 0.5960\nEpoch 46/100\n1093/1093 [==============================] - 0s 76us/step - loss: 0.7371 - mean_absolute_error: 0.7371 - val_loss: 0.6786 - val_mean_absolute_error: 0.6786\nEpoch 47/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.7416 - mean_absolute_error: 0.7416 - val_loss: 0.5581 - val_mean_absolute_error: 0.5581\nEpoch 48/100\n1093/1093 [==============================] - 0s 71us/step - loss: 0.7574 - mean_absolute_error: 0.7574 - val_loss: 0.6864 - val_mean_absolute_error: 0.6864\nEpoch 49/100\n1093/1093 [==============================] - 0s 71us/step - loss: 0.7125 - mean_absolute_error: 0.7125 - val_loss: 0.5986 - val_mean_absolute_error: 0.5986\nEpoch 50/100\n1093/1093 [==============================] - 0s 72us/step - loss: 0.6886 - mean_absolute_error: 0.6886 - val_loss: 0.4811 - val_mean_absolute_error: 0.4811\nEpoch 51/100\n1093/1093 [==============================] - 0s 72us/step - loss: 0.7491 - mean_absolute_error: 0.7491 - val_loss: 0.5116 - val_mean_absolute_error: 0.5116\nEpoch 52/100\n1093/1093 [==============================] - 0s 76us/step - loss: 0.7610 - mean_absolute_error: 0.7610 - val_loss: 0.4961 - val_mean_absolute_error: 0.4961\nEpoch 53/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.7235 - mean_absolute_error: 0.7235 - val_loss: 0.4806 - val_mean_absolute_error: 0.4806\nEpoch 54/100\n1093/1093 [==============================] - 0s 74us/step - loss: 0.7264 - mean_absolute_error: 0.7264 - val_loss: 0.4402 - val_mean_absolute_error: 0.4402\nEpoch 55/100\n1093/1093 [==============================] - 0s 74us/step - loss: 0.6924 - mean_absolute_error: 0.6924 - val_loss: 0.4423 - val_mean_absolute_error: 0.4423\nEpoch 56/100\n1093/1093 [==============================] - 0s 71us/step - loss: 0.7234 - mean_absolute_error: 0.7234 - val_loss: 0.4971 - val_mean_absolute_error: 0.4971\nEpoch 57/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.7093 - mean_absolute_error: 0.7093 - val_loss: 0.4556 - val_mean_absolute_error: 0.4556\nEpoch 58/100\n1093/1093 [==============================] - 0s 79us/step - loss: 0.7055 - mean_absolute_error: 0.7055 - val_loss: 0.4751 - val_mean_absolute_error: 0.4751\nEpoch 59/100\n1093/1093 [==============================] - 0s 86us/step - loss: 0.6886 - mean_absolute_error: 0.6886 - val_loss: 0.5043 - val_mean_absolute_error: 0.5043\nEpoch 60/100\n1093/1093 [==============================] - 0s 79us/step - loss: 0.7237 - mean_absolute_error: 0.7237 - val_loss: 0.4770 - val_mean_absolute_error: 0.4770\nEpoch 61/100\n1093/1093 [==============================] - 0s 76us/step - loss: 0.7373 - mean_absolute_error: 0.7373 - val_loss: 0.6264 - val_mean_absolute_error: 0.6264\nEpoch 62/100\n1093/1093 [==============================] - 0s 76us/step - loss: 0.7299 - mean_absolute_error: 0.7299 - val_loss: 0.5774 - val_mean_absolute_error: 0.5774\nEpoch 63/100\n1093/1093 [==============================] - 0s 77us/step - loss: 0.6998 - mean_absolute_error: 0.6998 - val_loss: 0.5829 - val_mean_absolute_error: 0.5829\nEpoch 64/100\n1093/1093 [==============================] - 0s 75us/step - loss: 0.6918 - mean_absolute_error: 0.6918 - val_loss: 0.5879 - val_mean_absolute_error: 0.5879\nEpoch 65/100\n1093/1093 [==============================] - 0s 75us/step - loss: 0.7251 - mean_absolute_error: 0.7251 - val_loss: 0.5644 - val_mean_absolute_error: 0.5644\nEpoch 66/100\n1093/1093 [==============================] - 0s 76us/step - loss: 0.6868 - mean_absolute_error: 0.6868 - val_loss: 0.4814 - val_mean_absolute_error: 0.4814\nEpoch 67/100\n1093/1093 [==============================] - 0s 76us/step - loss: 0.7042 - mean_absolute_error: 0.7042 - val_loss: 0.4738 - val_mean_absolute_error: 0.4738\nEpoch 68/100\n1093/1093 [==============================] - 0s 75us/step - loss: 0.7004 - mean_absolute_error: 0.7004 - val_loss: 0.4956 - val_mean_absolute_error: 0.4956\nEpoch 69/100\n1093/1093 [==============================] - 0s 75us/step - loss: 0.6808 - mean_absolute_error: 0.6808 - val_loss: 0.5061 - val_mean_absolute_error: 0.5061\nEpoch 70/100\n1093/1093 [==============================] - 0s 87us/step - loss: 0.6881 - mean_absolute_error: 0.6881 - val_loss: 0.4873 - val_mean_absolute_error: 0.4873\nEpoch 71/100\n1093/1093 [==============================] - 0s 78us/step - loss: 0.6912 - mean_absolute_error: 0.6912 - val_loss: 0.5177 - val_mean_absolute_error: 0.5177\nEpoch 72/100\n1093/1093 [==============================] - 0s 77us/step - loss: 0.6972 - mean_absolute_error: 0.6972 - val_loss: 0.4781 - val_mean_absolute_error: 0.4781\nEpoch 73/100\n1093/1093 [==============================] - 0s 74us/step - loss: 0.6796 - mean_absolute_error: 0.6796 - val_loss: 0.5216 - val_mean_absolute_error: 0.5216\nEpoch 74/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.7073 - mean_absolute_error: 0.7073 - val_loss: 0.5096 - val_mean_absolute_error: 0.5096\nEpoch 75/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.7023 - mean_absolute_error: 0.7023 - val_loss: 0.5566 - val_mean_absolute_error: 0.5566\nEpoch 76/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.6619 - mean_absolute_error: 0.6619 - val_loss: 0.5376 - val_mean_absolute_error: 0.5376\nEpoch 77/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.6997 - mean_absolute_error: 0.6997 - val_loss: 0.6439 - val_mean_absolute_error: 0.6439\nEpoch 78/100\n1093/1093 [==============================] - 0s 72us/step - loss: 0.7114 - mean_absolute_error: 0.7114 - val_loss: 0.7678 - val_mean_absolute_error: 0.7678\nEpoch 79/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.7320 - mean_absolute_error: 0.7320 - val_loss: 0.6713 - val_mean_absolute_error: 0.6713\nEpoch 80/100\n1093/1093 [==============================] - 0s 73us/step - loss: 0.7255 - mean_absolute_error: 0.7255 - val_loss: 0.5277 - val_mean_absolute_error: 0.5277\nEpoch 81/100\n1093/1093 [==============================] - 0s 74us/step - loss: 0.7002 - mean_absolute_error: 0.7002 - val_loss: 0.4669 - val_mean_absolute_error: 0.4669\nEpoch 82/100\n1093/1093 [==============================] - 0s 83us/step - loss: 0.6838 - mean_absolute_error: 0.6838 - val_loss: 0.4671 - val_mean_absolute_error: 0.4671\nEpoch 83/100\n1093/1093 [==============================] - 0s 84us/step - loss: 0.7239 - mean_absolute_error: 0.7239 - val_loss: 0.4548 - val_mean_absolute_error: 0.4548\nEpoch 84/100\n1093/1093 [==============================] - 0s 78us/step - loss: 0.7215 - mean_absolute_error: 0.7215 - val_loss: 0.4696 - val_mean_absolute_error: 0.4696\nEpoch 85/100\n1093/1093 [==============================] - 0s 81us/step - loss: 0.6916 - mean_absolute_error: 0.6916 - val_loss: 0.4691 - val_mean_absolute_error: 0.4691\nEpoch 86/100\n1093/1093 [==============================] - 0s 82us/step - loss: 0.7154 - mean_absolute_error: 0.7154 - val_loss: 0.5024 - val_mean_absolute_error: 0.5024\nEpoch 87/100\n1093/1093 [==============================] - 0s 78us/step - loss: 0.6581 - mean_absolute_error: 0.6581 - val_loss: 0.4508 - val_mean_absolute_error: 0.4508\nEpoch 88/100\n1093/1093 [==============================] - 0s 91us/step - loss: 0.6741 - mean_absolute_error: 0.6741 - val_loss: 0.5264 - val_mean_absolute_error: 0.5264\nEpoch 89/100\n1093/1093 [==============================] - 0s 85us/step - loss: 0.6758 - mean_absolute_error: 0.6758 - val_loss: 0.4615 - val_mean_absolute_error: 0.4615\nEpoch 90/100\n1093/1093 [==============================] - 0s 84us/step - loss: 0.6615 - mean_absolute_error: 0.6615 - val_loss: 0.5141 - val_mean_absolute_error: 0.5141\nEpoch 91/100\n1093/1093 [==============================] - 0s 84us/step - loss: 0.6895 - mean_absolute_error: 0.6895 - val_loss: 0.5816 - val_mean_absolute_error: 0.5816\nEpoch 92/100\n1093/1093 [==============================] - 0s 83us/step - loss: 0.6334 - mean_absolute_error: 0.6334 - val_loss: 0.4586 - val_mean_absolute_error: 0.4586\nEpoch 93/100\n1093/1093 [==============================] - 0s 90us/step - loss: 0.6586 - mean_absolute_error: 0.6586 - val_loss: 0.5563 - val_mean_absolute_error: 0.5563\nEpoch 94/100\n1093/1093 [==============================] - 0s 89us/step - loss: 0.6424 - mean_absolute_error: 0.6424 - val_loss: 0.5265 - val_mean_absolute_error: 0.5265\nEpoch 95/100\n1093/1093 [==============================] - 0s 87us/step - loss: 0.6509 - mean_absolute_error: 0.6509 - val_loss: 0.4915 - val_mean_absolute_error: 0.4915\nEpoch 96/100\n1093/1093 [==============================] - 0s 87us/step - loss: 0.6765 - mean_absolute_error: 0.6765 - val_loss: 0.5119 - val_mean_absolute_error: 0.5119\nEpoch 97/100\n1093/1093 [==============================] - 0s 88us/step - loss: 0.6750 - mean_absolute_error: 0.6750 - val_loss: 0.4955 - val_mean_absolute_error: 0.4955\nEpoch 98/100\n1093/1093 [==============================] - 0s 88us/step - loss: 0.6663 - mean_absolute_error: 0.6663 - val_loss: 0.5903 - val_mean_absolute_error: 0.5903\nEpoch 99/100\n1093/1093 [==============================] - 0s 88us/step - loss: 0.6779 - mean_absolute_error: 0.6779 - val_loss: 0.6000 - val_mean_absolute_error: 0.6000\nEpoch 100/100\n1093/1093 [==============================] - 0s 88us/step - loss: 0.6672 - mean_absolute_error: 0.6672 - val_loss: 0.5625 - val_mean_absolute_error: 0.5625\nmean_absolute_error: 0.5560\n"
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-804e963a0544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# 予測\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# -----------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_x' is not defined"
     ]
    }
   ],
   "source": [
    "# 学習データを学習データとバリデーションデータに分ける\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "# tensorflowの警告抑制\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# -----------------------------------\n",
    "# ニューラルネットの実装\n",
    "# -----------------------------------\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# データのスケーリング\n",
    "scaler = StandardScaler()\n",
    "tr_x = scaler.fit_transform(tr_x)\n",
    "va_x = scaler.transform(va_x)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "# ニューラルネットモデルの構築\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(train_x.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# The Output Layer :\n",
    "model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "\n",
    "# 学習の実行\n",
    "# バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "history = model.fit(tr_x, tr_y,\n",
    "                    batch_size=batch_size, epochs=epochs,\n",
    "                    verbose=1, validation_data=(va_x, va_y))\n",
    "\n",
    "# バリデーションデータでのスコアの確認\n",
    "va_pred = model.predict(va_x)\n",
    "score = mean_squared_error(va_y, va_pred)\n",
    "print(f'mean_absolute_error: {score:.4f}')\n",
    "\n",
    "# 予測\n",
    "pred = model.predict(test_x)\n",
    "\n",
    "# -----------------------------------\n",
    "# アーリーストッピング\n",
    "# -----------------------------------\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# アーリーストッピングの観察するroundを20とする\n",
    "# restore_best_weightsを設定することで、最適なエポックでのモデルを使用する\n",
    "epochs = 100\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(tr_x, tr_y,\n",
    "                    batch_size=batch_size, epochs=epochs,\n",
    "                    verbose=1, validation_data=(va_x, va_y), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 88390.25],\n       [205928.98],\n       [101749.03],\n       ...,\n       [258149.73],\n       [ 76431.08],\n       [242722.5 ]], dtype=float32)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "221"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}